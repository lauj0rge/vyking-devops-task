# üß™ Cluster Test Results for `dev`

## üìã Summary
- **Generated:** 2025-09-19 23:34:46 CEST
- **Environment:** `dev`
- **Cluster Name:** `vyking-dev`
- **Argo CD Namespace:** `argocd-dev`

## üß≠ Access Checks
### kubectl version --short
```bash
+ kubectl version --short
error: unknown flag: --short
See 'kubectl version --help' for usage.

[command failed with exit code 1]
```

### Current context
```bash
+ kubectl config current-context
k3d-vyking-dev
```

### Available contexts
```bash
+ kubectl config get-contexts
CURRENT   NAME             CLUSTER          AUTHINFO               NAMESPACE
*         k3d-vyking-dev   k3d-vyking-dev   admin@k3d-vyking-dev   
```

## üåê Cluster Overview
### Cluster info
```bash
+ kubectl cluster-info
Kubernetes control plane is running at https://0.0.0.0:41245
CoreDNS is running at https://0.0.0.0:41245/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://0.0.0.0:41245/api/v1/namespaces/kube-system/services/https:metrics-server:https/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```

### Nodes
```bash
+ kubectl get nodes -o wide
NAME                      STATUS   ROLES                  AGE    VERSION        INTERNAL-IP   EXTERNAL-IP   OS-IMAGE           KERNEL-VERSION     CONTAINER-RUNTIME
k3d-vyking-dev-agent-0    Ready    <none>                 123m   v1.31.5+k3s1   172.18.0.3    <none>        K3s v1.31.5+k3s1   6.8.0-79-generic   containerd://1.7.23-k3s2
k3d-vyking-dev-agent-1    Ready    <none>                 123m   v1.31.5+k3s1   172.18.0.4    <none>        K3s v1.31.5+k3s1   6.8.0-79-generic   containerd://1.7.23-k3s2
k3d-vyking-dev-server-0   Ready    control-plane,master   123m   v1.31.5+k3s1   172.18.0.2    <none>        K3s v1.31.5+k3s1   6.8.0-79-generic   containerd://1.7.23-k3s2
```

### Namespaces
```bash
+ kubectl get ns
NAME              STATUS   AGE
argocd-dev        Active   113m
backend-dev       Active   106m
cert-manager      Active   107m
default           Active   123m
frontend-dev      Active   106m
ingress-nginx     Active   106m
kube-node-lease   Active   123m
kube-public       Active   123m
kube-system       Active   123m
mysql-dev         Active   108m
```

### Pods (all namespaces)
```bash
+ kubectl get pods -A -o wide
NAMESPACE       NAME                                                READY   STATUS      RESTARTS   AGE     IP           NODE                      NOMINATED NODE   READINESS GATES
argocd-dev      argocd-application-controller-0                     1/1     Running     0          111m    10.42.0.6    k3d-vyking-dev-agent-0    <none>           <none>
argocd-dev      argocd-applicationset-controller-78f49df558-679r4   1/1     Running     0          111m    10.42.2.7    k3d-vyking-dev-server-0   <none>           <none>
argocd-dev      argocd-dex-server-796678d5bc-qv7s7                  1/1     Running     0          111m    10.42.0.5    k3d-vyking-dev-agent-0    <none>           <none>
argocd-dev      argocd-notifications-controller-6d84bf8458-5tftw    1/1     Running     0          111m    10.42.1.7    k3d-vyking-dev-agent-1    <none>           <none>
argocd-dev      argocd-redis-7c7fb7fc74-cmkr7                       1/1     Running     0          111m    10.42.1.6    k3d-vyking-dev-agent-1    <none>           <none>
argocd-dev      argocd-repo-server-d587f667c-5w8z8                  1/1     Running     0          111m    10.42.2.8    k3d-vyking-dev-server-0   <none>           <none>
argocd-dev      argocd-server-556b554c94-nln6q                      1/1     Running     0          111m    10.42.2.6    k3d-vyking-dev-server-0   <none>           <none>
backend-dev     backend-backend-66c96df8b-j8pcg                     1/1     Running     0          4m10s   10.42.0.43   k3d-vyking-dev-agent-0    <none>           <none>
backend-dev     backend-backend-66c96df8b-kgsvt                     1/1     Running     0          105m    10.42.1.9    k3d-vyking-dev-agent-1    <none>           <none>
cert-manager    cert-manager-55c69bf5cf-jzfd4                       1/1     Running     0          107m    10.42.0.7    k3d-vyking-dev-agent-0    <none>           <none>
cert-manager    cert-manager-cainjector-5765b5f544-hjj6k            1/1     Running     0          107m    10.42.2.9    k3d-vyking-dev-server-0   <none>           <none>
cert-manager    cert-manager-webhook-6b67444dc9-k2q5r               1/1     Running     0          107m    10.42.1.8    k3d-vyking-dev-agent-1    <none>           <none>
frontend-dev    frontend-frontend-597d68f8cf-jrz92                  1/1     Running     0          105m    10.42.2.12   k3d-vyking-dev-server-0   <none>           <none>
ingress-nginx   ingress-nginx-controller-b4b575f8-7824d             1/1     Running     0          105m    10.42.2.13   k3d-vyking-dev-server-0   <none>           <none>
kube-system     coredns-ccb96694c-w552h                             1/1     Running     0          123m    10.42.1.3    k3d-vyking-dev-agent-1    <none>           <none>
kube-system     helm-install-traefik-8bp89                          0/1     Completed   1          123m    10.42.2.2    k3d-vyking-dev-server-0   <none>           <none>
kube-system     helm-install-traefik-crd-d7bpc                      0/1     Completed   0          123m    10.42.1.2    k3d-vyking-dev-agent-1    <none>           <none>
kube-system     local-path-provisioner-5cf85fd84d-2blrh             1/1     Running     0          123m    10.42.2.3    k3d-vyking-dev-server-0   <none>           <none>
kube-system     metrics-server-5985cbc9d7-hsgtx                     1/1     Running     0          123m    10.42.0.2    k3d-vyking-dev-agent-0    <none>           <none>
kube-system     sealed-secrets-controller-5655858cbc-9xzgr          1/1     Running     0          123m    10.42.0.3    k3d-vyking-dev-agent-0    <none>           <none>
kube-system     svclb-traefik-5d2bd1f3-4s6hk                        2/2     Running     0          121m    10.42.0.4    k3d-vyking-dev-agent-0    <none>           <none>
kube-system     svclb-traefik-5d2bd1f3-k8fvv                        2/2     Running     0          121m    10.42.1.5    k3d-vyking-dev-agent-1    <none>           <none>
kube-system     svclb-traefik-5d2bd1f3-qhsgs                        2/2     Running     0          121m    10.42.2.4    k3d-vyking-dev-server-0   <none>           <none>
kube-system     traefik-5d45fc8cc9-w6xl2                            1/1     Running     0          121m    10.42.1.4    k3d-vyking-dev-agent-1    <none>           <none>
mysql-dev       mysql-0                                             1/1     Running     0          79m     10.42.1.12   k3d-vyking-dev-agent-1    <none>           <none>
mysql-dev       tmp-shell                                           1/1     Running     0          11m     10.42.2.19   k3d-vyking-dev-server-0   <none>           <none>
```

### Services (all namespaces)
```bash
+ kubectl get svc -A -o wide
NAMESPACE       NAME                                    TYPE           CLUSTER-IP      EXTERNAL-IP                        PORT(S)                      AGE    SELECTOR
argocd-dev      argocd-application-controller-metrics   ClusterIP      10.43.23.78     <none>                             8082/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-application-controller
argocd-dev      argocd-applicationset-controller        ClusterIP      10.43.144.31    <none>                             7000/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-applicationset-controller
argocd-dev      argocd-dex-server                       ClusterIP      10.43.58.182    <none>                             5556/TCP,5557/TCP,5558/TCP   111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-dex-server
argocd-dev      argocd-redis                            ClusterIP      10.43.209.222   <none>                             6379/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-redis
argocd-dev      argocd-redis-metrics                    ClusterIP      None            <none>                             9121/TCP                     111m   app.kubernetes.io/component=redis,app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-redis
argocd-dev      argocd-repo-server                      ClusterIP      10.43.156.205   <none>                             8081/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-repo-server
argocd-dev      argocd-repo-server-metrics              ClusterIP      10.43.85.105    <none>                             8084/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-repo-server
argocd-dev      argocd-server                           ClusterIP      10.43.217.184   <none>                             80/TCP,443/TCP               111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-server
backend-dev     backend-backend                         ClusterIP      10.43.231.3     <none>                             8081/TCP                     105m   app=backend-backend
cert-manager    cert-manager                            ClusterIP      10.43.211.209   <none>                             9402/TCP                     107m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=cert-manager
cert-manager    cert-manager-cainjector                 ClusterIP      10.43.14.233    <none>                             9402/TCP                     107m   app.kubernetes.io/component=cainjector,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=cainjector
cert-manager    cert-manager-webhook                    ClusterIP      10.43.193.48    <none>                             443/TCP,9402/TCP             107m   app.kubernetes.io/component=webhook,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=webhook
default         kubernetes                              ClusterIP      10.43.0.1       <none>                             443/TCP                      123m   <none>
frontend-dev    frontend-frontend                       ClusterIP      10.43.174.103   <none>                             8080/TCP                     105m   app=frontend-frontend
ingress-nginx   ingress-nginx-controller                NodePort       10.43.140.62    <none>                             80:31100/TCP,443:30118/TCP   105m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx
ingress-nginx   ingress-nginx-controller-admission      ClusterIP      10.43.224.21    <none>                             443/TCP                      105m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx
kube-system     kube-dns                                ClusterIP      10.43.0.10      <none>                             53/UDP,53/TCP,9153/TCP       123m   k8s-app=kube-dns
kube-system     metrics-server                          ClusterIP      10.43.153.135   <none>                             443/TCP                      123m   k8s-app=metrics-server
kube-system     sealed-secrets-controller               ClusterIP      10.43.252.105   <none>                             8080/TCP                     123m   name=sealed-secrets-controller
kube-system     sealed-secrets-controller-metrics       ClusterIP      10.43.171.153   <none>                             8081/TCP                     123m   name=sealed-secrets-controller
kube-system     traefik                                 LoadBalancer   10.43.192.148   172.18.0.2,172.18.0.3,172.18.0.4   80:30496/TCP,443:30857/TCP   121m   app.kubernetes.io/instance=traefik-kube-system,app.kubernetes.io/name=traefik
mysql-dev       mysql                                   ClusterIP      10.43.182.98    <none>                             3306/TCP                     79m    app.kubernetes.io/component=primary,app.kubernetes.io/instance=mysql,app.kubernetes.io/name=mysql,app.kubernetes.io/part-of=mysql
mysql-dev       mysql-headless                          ClusterIP      None            <none>                             3306/TCP                     79m    app.kubernetes.io/component=primary,app.kubernetes.io/instance=mysql,app.kubernetes.io/name=mysql
```

### Ingresses (all namespaces)
```bash
+ kubectl get ingress -A
NAMESPACE      NAME                CLASS     HOSTS                ADDRESS                            PORTS     AGE
backend-dev    backend-backend     traefik   frontend-dev.local   172.18.0.2,172.18.0.3,172.18.0.4   80        105m
frontend-dev   frontend-frontend   <none>    frontend-dev.local   10.43.140.62                       80, 443   105m
```

### Deployments (all namespaces)
```bash
+ kubectl get deploy -A
NAMESPACE       NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
argocd-dev      argocd-applicationset-controller   1/1     1            1           111m
argocd-dev      argocd-dex-server                  1/1     1            1           111m
argocd-dev      argocd-notifications-controller    1/1     1            1           111m
argocd-dev      argocd-redis                       1/1     1            1           111m
argocd-dev      argocd-repo-server                 1/1     1            1           111m
argocd-dev      argocd-server                      1/1     1            1           111m
backend-dev     backend-backend                    2/2     2            2           105m
cert-manager    cert-manager                       1/1     1            1           107m
cert-manager    cert-manager-cainjector            1/1     1            1           107m
cert-manager    cert-manager-webhook               1/1     1            1           107m
frontend-dev    frontend-frontend                  1/1     1            1           105m
ingress-nginx   ingress-nginx-controller           1/1     1            1           105m
kube-system     coredns                            1/1     1            1           123m
kube-system     local-path-provisioner             1/1     1            1           123m
kube-system     metrics-server                     1/1     1            1           123m
kube-system     sealed-secrets-controller          1/1     1            1           123m
kube-system     traefik                            1/1     1            1           121m
```

### StatefulSets (all namespaces)
```bash
+ kubectl get statefulset -A
NAMESPACE    NAME                            READY   AGE
argocd-dev   argocd-application-controller   1/1     111m
mysql-dev    mysql                           1/1     79m
```

### DaemonSets (all namespaces)
```bash
+ kubectl get daemonset -A
NAMESPACE     NAME                     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
kube-system   svclb-traefik-5d2bd1f3   3         3         3       3            3           <none>          121m
```

### PersistentVolumeClaims (all namespaces)
```bash
+ kubectl get pvc -A
NAMESPACE   NAME            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
mysql-dev   data-mysql-0    Bound    pvc-2300a91d-3838-4354-8dfa-3e859648462a   8Gi        RWO            local-path     <unset>                 79m
mysql-dev   mysql-backups   Bound    pvc-4d48fb6d-0b76-4ffb-9cdd-acdd00097e43   2Gi        RWO            local-path     <unset>                 79m
```

### PersistentVolumes
```bash
+ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                     STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pvc-2300a91d-3838-4354-8dfa-3e859648462a   8Gi        RWO            Delete           Bound    mysql-dev/data-mysql-0    local-path     <unset>                          78m
pvc-4d48fb6d-0b76-4ffb-9cdd-acdd00097e43   2Gi        RWO            Delete           Bound    mysql-dev/mysql-backups   local-path     <unset>                          74m
```

### StorageClasses
```bash
+ kubectl get storageclass
NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  123m
```

### Jobs (all namespaces)
```bash
+ kubectl get jobs -A
NAMESPACE     NAME                       STATUS     COMPLETIONS   DURATION   AGE
kube-system   helm-install-traefik       Complete   1/1           115s       123m
kube-system   helm-install-traefik-crd   Complete   1/1           108s       123m
```

### CronJobs (all namespaces)
```bash
+ kubectl get cronjobs -A
NAMESPACE   NAME           SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE
mysql-dev   mysql-backup   */5 * * * *   <none>     False     0        4m51s           79m
```

### Horizontal Pod Autoscalers (all namespaces)
```bash
+ kubectl get hpa -A
NAMESPACE      NAME                REFERENCE                      TARGETS                        MINPODS   MAXPODS   REPLICAS   AGE
backend-dev    backend-backend     Deployment/backend-backend     cpu: 1%/70%, memory: 19%/70%   1         5         2          105m
frontend-dev   frontend-frontend   Deployment/frontend-frontend   cpu: 1%/70%, memory: 3%/80%    1         3         1          105m
```

### Resource usage (nodes)
```bash
+ kubectl top nodes
NAME                      CPU(cores)   CPU(%)   MEMORY(bytes)   MEMORY(%)   
k3d-vyking-dev-agent-0    261m         8%       538Mi           6%          
k3d-vyking-dev-agent-1    291m         9%       758Mi           9%          
k3d-vyking-dev-server-0   287m         9%       1195Mi          15%         
```

### Resource usage (pods, all namespaces)
```bash
+ kubectl top pods -A
NAMESPACE       NAME                                                CPU(cores)   MEMORY(bytes)   
argocd-dev      argocd-application-controller-0                     17m          208Mi           
argocd-dev      argocd-applicationset-controller-78f49df558-679r4   5m           22Mi            
argocd-dev      argocd-dex-server-796678d5bc-qv7s7                  2m           26Mi            
argocd-dev      argocd-notifications-controller-6d84bf8458-5tftw    1m           25Mi            
argocd-dev      argocd-redis-7c7fb7fc74-cmkr7                       4m           3Mi             
argocd-dev      argocd-repo-server-d587f667c-5w8z8                  2m           95Mi            
argocd-dev      argocd-server-556b554c94-nln6q                      4m           69Mi            
backend-dev     backend-backend-66c96df8b-j8pcg                     1m           24Mi            
backend-dev     backend-backend-66c96df8b-kgsvt                     1m           25Mi            
cert-manager    cert-manager-55c69bf5cf-jzfd4                       5m           23Mi            
cert-manager    cert-manager-cainjector-5765b5f544-hjj6k            8m           22Mi            
cert-manager    cert-manager-webhook-6b67444dc9-k2q5r               2m           12Mi            
frontend-dev    frontend-frontend-597d68f8cf-jrz92                  1m           4Mi             
ingress-nginx   ingress-nginx-controller-b4b575f8-7824d             4m           56Mi            
kube-system     coredns-ccb96694c-w552h                             7m           17Mi            
kube-system     local-path-provisioner-5cf85fd84d-2blrh             1m           10Mi            
kube-system     metrics-server-5985cbc9d7-hsgtx                     19m          24Mi            
kube-system     sealed-secrets-controller-5655858cbc-9xzgr          1m           10Mi            
kube-system     svclb-traefik-5d2bd1f3-4s6hk                        0m           0Mi             
kube-system     svclb-traefik-5d2bd1f3-k8fvv                        0m           0Mi             
kube-system     svclb-traefik-5d2bd1f3-qhsgs                        0m           0Mi             
kube-system     traefik-5d45fc8cc9-w6xl2                            3m           38Mi            
mysql-dev       mysql-0                                             36m          437Mi           
mysql-dev       tmp-shell                                           0m           0Mi             
```

### Recent cluster events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -A\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 40
argocd-dev    9m29s       Normal    OperationCompleted       application/backend                       Sync operation to f04ea123dfb225fd4bcfb7b04381897fd7ce7420 succeeded
backend-dev   9m29s       Normal    Scheduled                pod/backend-backend-66c96df8b-nbphp       Successfully assigned backend-dev/backend-backend-66c96df8b-nbphp to k3d-vyking-dev-agent-0
backend-dev   9m27s       Normal    Created                  pod/backend-backend-66c96df8b-nbphp       Created container backend
backend-dev   9m27s       Normal    Pulled                   pod/backend-backend-66c96df8b-nbphp       Container image "vyking-backend:dev" already present on machine
backend-dev   9m26s       Normal    Started                  pod/backend-backend-66c96df8b-nbphp       Started container backend
argocd-dev    8m58s       Normal    ResourceUpdated          application/backend                       Updated health status: Progressing -> Healthy
mysql-dev     8m22s       Normal    Started                  pod/tmp-shell                             Started container tmp-shell
mysql-dev     8m22s       Normal    Created                  pod/tmp-shell                             Created container tmp-shell
mysql-dev     8m22s       Normal    Pulled                   pod/tmp-shell                             Successfully pulled image "bitnami/mysql:8.0" in 3m0.581s (3m0.582s including waiting). Image size: 239770540 bytes.
argocd-dev    5m41s       Normal    ResourceDeleted          application/mysql                         admin deleted resource batch/Job 'mysql-backup-29305285'
mysql-dev     5m38s       Normal    MissingJob               cronjob/mysql-backup                      Active job went missing: mysql-backup-29305285
argocd-dev    5m34s       Normal    OperationStarted         application/mysql                         admin initiated sync to dev (ab23102ddd7c2f482f0da6250fee09ab6e3045cc)
mysql-dev     4m52s       Normal    SuccessfulCreate         job/mysql-backup-29305290                 Created pod: mysql-backup-29305290-2d9vr
mysql-dev     4m52s       Normal    Scheduled                pod/mysql-backup-29305290-2d9vr           Successfully assigned mysql-dev/mysql-backup-29305290-2d9vr to k3d-vyking-dev-agent-0
mysql-dev     2m37s       Warning   Failed                   pod/mysql-backup-29305290-2d9vr           Error: couldn't find key userPassword in Secret mysql-dev/mysql-dev-secret
mysql-dev     2m37s       Normal    Pulled                   pod/mysql-backup-29305290-2d9vr           Container image "bitnami/mysql:8.0" already present on machine
argocd-dev    4m34s       Warning   OperationCompleted       application/mysql                         Sync operation to  failed: ComparisonError: Failed to load target state: failed to generate manifest for source 1 of 1: rpc error: code = DeadlineExceeded desc = context deadline exceeded
argocd-dev    4m29s       Normal    ResourceUpdated          application/mysql                         Updated sync status: Synced -> OutOfSync
argocd-dev    4m29s       Normal    OperationStarted         application/mysql                         Initiated automated sync to 'ab23102ddd7c2f482f0da6250fee09ab6e3045cc'
argocd-dev    4m22s       Normal    ResourceUpdated          application/mysql                         Updated sync status: OutOfSync -> Synced
argocd-dev    4m22s       Normal    OperationCompleted       application/mysql                         Sync operation to ab23102ddd7c2f482f0da6250fee09ab6e3045cc succeeded
backend-dev   4m16s       Normal    Killing                  pod/backend-backend-66c96df8b-nbphp       Stopping container backend
argocd-dev    4m15s       Normal    OperationStarted         application/backend                       Initiated automated sync to 'f04ea123dfb225fd4bcfb7b04381897fd7ce7420'
argocd-dev    4m15s       Normal    ResourceUpdated          application/backend                       Updated sync status: Synced -> OutOfSync
argocd-dev    4m14s       Normal    ResourceUpdated          application/backend                       Updated health status: Healthy -> Progressing
backend-dev   4m13s       Normal    Scheduled                pod/backend-backend-66c96df8b-j8pcg       Successfully assigned backend-dev/backend-backend-66c96df8b-j8pcg to k3d-vyking-dev-agent-0
argocd-dev    4m14s       Normal    OperationCompleted       application/backend                       Partial sync operation to f04ea123dfb225fd4bcfb7b04381897fd7ce7420 succeeded
argocd-dev    4m14s       Normal    ResourceUpdated          application/backend                       Updated sync status: OutOfSync -> Synced
backend-dev   4m11s       Normal    Created                  pod/backend-backend-66c96df8b-j8pcg       Created container backend
backend-dev   4m11s       Normal    Pulled                   pod/backend-backend-66c96df8b-j8pcg       Container image "vyking-backend:dev" already present on machine
backend-dev   4m10s       Normal    Started                  pod/backend-backend-66c96df8b-j8pcg       Started container backend
argocd-dev    3m43s       Normal    ResourceUpdated          application/backend                       Updated health status: Progressing -> Healthy
argocd-dev    2m45s       Normal    OperationStarted         application/mysql                         admin initiated sync to dev (e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45)
argocd-dev    2m36s       Normal    ResourceDeleted          application/mysql                         admin deleted resource batch/Job 'mysql-backup-29305290'
mysql-dev     2m33s       Normal    MissingJob               cronjob/mysql-backup                      Active job went missing: mysql-backup-29305290
argocd-dev    107s        Normal    ResourceUpdated          application/mysql                         Updated sync status: Synced -> OutOfSync
argocd-dev    103s        Normal    OperationCompleted       application/mysql                         Sync operation to e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45 succeeded
argocd-dev    103s        Normal    ResourceUpdated          application/mysql                         Updated sync status: OutOfSync -> Synced
argocd-dev    71s         Normal    OperationStarted         application/mysql                         admin initiated sync to dev (e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45)
argocd-dev    67s         Normal    OperationCompleted       application/mysql                         Sync operation to e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45 succeeded
```

## üö¶ Argo CD (`argocd-dev`)
### Pods
```bash
+ kubectl get pods -n argocd-dev -o wide
NAME                                                READY   STATUS    RESTARTS   AGE    IP          NODE                      NOMINATED NODE   READINESS GATES
argocd-application-controller-0                     1/1     Running   0          111m   10.42.0.6   k3d-vyking-dev-agent-0    <none>           <none>
argocd-applicationset-controller-78f49df558-679r4   1/1     Running   0          111m   10.42.2.7   k3d-vyking-dev-server-0   <none>           <none>
argocd-dex-server-796678d5bc-qv7s7                  1/1     Running   0          111m   10.42.0.5   k3d-vyking-dev-agent-0    <none>           <none>
argocd-notifications-controller-6d84bf8458-5tftw    1/1     Running   0          111m   10.42.1.7   k3d-vyking-dev-agent-1    <none>           <none>
argocd-redis-7c7fb7fc74-cmkr7                       1/1     Running   0          111m   10.42.1.6   k3d-vyking-dev-agent-1    <none>           <none>
argocd-repo-server-d587f667c-5w8z8                  1/1     Running   0          111m   10.42.2.8   k3d-vyking-dev-server-0   <none>           <none>
argocd-server-556b554c94-nln6q                      1/1     Running   0          111m   10.42.2.6   k3d-vyking-dev-server-0   <none>           <none>
```

### Deployments
```bash
+ kubectl get deploy -n argocd-dev -o wide
NAME                               READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS                  IMAGES                                                 SELECTOR
argocd-applicationset-controller   1/1     1            1           111m   applicationset-controller   quay.io/argoproj/argocd:v3.1.5                         app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-applicationset-controller
argocd-dex-server                  1/1     1            1           111m   dex-server                  ghcr.io/dexidp/dex:v2.44.0                             app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-dex-server
argocd-notifications-controller    1/1     1            1           111m   notifications-controller    quay.io/argoproj/argocd:v3.1.5                         app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-notifications-controller
argocd-redis                       1/1     1            1           111m   redis                       ecr-public.aws.com/docker/library/redis:7.2.8-alpine   app.kubernetes.io/name=argocd-redis
argocd-repo-server                 1/1     1            1           111m   repo-server                 quay.io/argoproj/argocd:v3.1.5                         app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-repo-server
argocd-server                      1/1     1            1           111m   server                      quay.io/argoproj/argocd:v3.1.5                         app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-server
```

### StatefulSets
```bash
+ kubectl get statefulset -n argocd-dev -o wide
NAME                            READY   AGE    CONTAINERS               IMAGES
argocd-application-controller   1/1     111m   application-controller   quay.io/argoproj/argocd:v3.1.5
```

### DaemonSets
```bash
+ kubectl get daemonset -n argocd-dev -o wide
No resources found in argocd-dev namespace.
```

### Services
```bash
+ kubectl get svc -n argocd-dev -o wide
NAME                                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE    SELECTOR
argocd-application-controller-metrics   ClusterIP   10.43.23.78     <none>        8082/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-application-controller
argocd-applicationset-controller        ClusterIP   10.43.144.31    <none>        7000/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-applicationset-controller
argocd-dex-server                       ClusterIP   10.43.58.182    <none>        5556/TCP,5557/TCP,5558/TCP   111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-dex-server
argocd-redis                            ClusterIP   10.43.209.222   <none>        6379/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-redis
argocd-redis-metrics                    ClusterIP   None            <none>        9121/TCP                     111m   app.kubernetes.io/component=redis,app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-redis
argocd-repo-server                      ClusterIP   10.43.156.205   <none>        8081/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-repo-server
argocd-repo-server-metrics              ClusterIP   10.43.85.105    <none>        8084/TCP                     111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-repo-server
argocd-server                           ClusterIP   10.43.217.184   <none>        80/TCP,443/TCP               111m   app.kubernetes.io/instance=argocd,app.kubernetes.io/name=argocd-server
```

### Ingresses
```bash
+ kubectl get ingress -n argocd-dev
No resources found in argocd-dev namespace.
```

### ConfigMaps
```bash
+ kubectl get configmap -n argocd-dev
NAME                            DATA   AGE
argocd-cm                       18     111m
argocd-cmd-params-cm            41     111m
argocd-gpg-keys-cm              0      111m
argocd-notifications-cm         1      111m
argocd-rbac-cm                  4      111m
argocd-redis-health-configmap   2      111m
argocd-ssh-known-hosts-cm       1      111m
argocd-tls-certs-cm             0      111m
kube-root-ca.crt                1      113m
```

### Secrets
```bash
+ kubectl get secret -n argocd-dev
NAME                           TYPE                 DATA   AGE
argocd-initial-admin-secret    Opaque               1      111m
argocd-notifications-secret    Opaque               0      111m
argocd-redis                   Opaque               1      112m
argocd-secret                  Opaque               3      111m
repo-vyking-git                Opaque               2      108m
sh.helm.release.v1.argocd.v1   helm.sh/release.v1   1      113m
```

### Horizontal Pod Autoscalers
```bash
+ kubectl get hpa -n argocd-dev
No resources found in argocd-dev namespace.
```

### Jobs
```bash
+ kubectl get jobs -n argocd-dev
No resources found in argocd-dev namespace.
```

### CronJobs
```bash
+ kubectl get cronjobs -n argocd-dev
No resources found in argocd-dev namespace.
```

### PersistentVolumeClaims
```bash
+ kubectl get pvc -n argocd-dev
No resources found in argocd-dev namespace.
```

### Recent Events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -n\ \"argocd-dev\"\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 20
5m45s       Normal    ResourceDeleted      application/mysql     admin deleted resource batch/Job 'mysql-backup-29305285'
5m38s       Normal    OperationStarted     application/mysql     admin initiated sync to dev (ab23102ddd7c2f482f0da6250fee09ab6e3045cc)
4m38s       Warning   OperationCompleted   application/mysql     Sync operation to  failed: ComparisonError: Failed to load target state: failed to generate manifest for source 1 of 1: rpc error: code = DeadlineExceeded desc = context deadline exceeded
4m33s       Normal    ResourceUpdated      application/mysql     Updated sync status: Synced -> OutOfSync
4m33s       Normal    OperationStarted     application/mysql     Initiated automated sync to 'ab23102ddd7c2f482f0da6250fee09ab6e3045cc'
4m26s       Normal    ResourceUpdated      application/mysql     Updated sync status: OutOfSync -> Synced
4m26s       Normal    OperationCompleted   application/mysql     Sync operation to ab23102ddd7c2f482f0da6250fee09ab6e3045cc succeeded
4m19s       Normal    ResourceUpdated      application/backend   Updated sync status: Synced -> OutOfSync
4m19s       Normal    OperationStarted     application/backend   Initiated automated sync to 'f04ea123dfb225fd4bcfb7b04381897fd7ce7420'
4m18s       Normal    ResourceUpdated      application/backend   Updated health status: Healthy -> Progressing
4m18s       Normal    ResourceUpdated      application/backend   Updated sync status: OutOfSync -> Synced
4m18s       Normal    OperationCompleted   application/backend   Partial sync operation to f04ea123dfb225fd4bcfb7b04381897fd7ce7420 succeeded
3m47s       Normal    ResourceUpdated      application/backend   Updated health status: Progressing -> Healthy
2m49s       Normal    OperationStarted     application/mysql     admin initiated sync to dev (e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45)
2m40s       Normal    ResourceDeleted      application/mysql     admin deleted resource batch/Job 'mysql-backup-29305290'
111s        Normal    ResourceUpdated      application/mysql     Updated sync status: Synced -> OutOfSync
107s        Normal    OperationCompleted   application/mysql     Sync operation to e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45 succeeded
107s        Normal    ResourceUpdated      application/mysql     Updated sync status: OutOfSync -> Synced
75s         Normal    OperationStarted     application/mysql     admin initiated sync to dev (e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45)
71s         Normal    OperationCompleted   application/mysql     Sync operation to e826d35d5dfc6c96dc552bbdbfa6c536ffda4b45 succeeded
```

### Resource Usage (pods)
```bash
+ kubectl top pods -n argocd-dev
NAME                                                CPU(cores)   MEMORY(bytes)   
argocd-application-controller-0                     17m          208Mi           
argocd-applicationset-controller-78f49df558-679r4   5m           22Mi            
argocd-dex-server-796678d5bc-qv7s7                  2m           26Mi            
argocd-notifications-controller-6d84bf8458-5tftw    1m           25Mi            
argocd-redis-7c7fb7fc74-cmkr7                       4m           3Mi             
argocd-repo-server-d587f667c-5w8z8                  2m           95Mi            
argocd-server-556b554c94-nln6q                      4m           69Mi            
```


### Applications
```bash
+ kubectl get applications -n argocd-dev
NAME                   SYNC STATUS   HEALTH STATUS
backend                Synced        Healthy
frontend               Synced        Healthy
mysql                  Synced        Healthy
mysql-sealed-secrets   Synced        Healthy
```

### ApplicationSets
```bash
+ kubectl get applicationsets -n argocd-dev
No resources found in argocd-dev namespace.
```

### AppProjects
```bash
+ kubectl get appprojects -n argocd-dev
NAME      AGE
default   111m
```

**UI:** [http://localhost:8080](http://localhost:8080)
**Port-forward command:**
```bash
kubectl port-forward svc/argocd-server -n argocd-dev 8080:80
```

## üé® Frontend (`frontend-dev`)
### Pods
```bash
+ kubectl get pods -n frontend-dev -o wide
NAME                                 READY   STATUS    RESTARTS   AGE    IP           NODE                      NOMINATED NODE   READINESS GATES
frontend-frontend-597d68f8cf-jrz92   1/1     Running   0          106m   10.42.2.12   k3d-vyking-dev-server-0   <none>           <none>
```

### Deployments
```bash
+ kubectl get deploy -n frontend-dev -o wide
NAME                READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES                SELECTOR
frontend-frontend   1/1     1            1           106m   frontend     vyking-frontend:dev   app=frontend-frontend
```

### StatefulSets
```bash
+ kubectl get statefulset -n frontend-dev -o wide
No resources found in frontend-dev namespace.
```

### DaemonSets
```bash
+ kubectl get daemonset -n frontend-dev -o wide
No resources found in frontend-dev namespace.
```

### Services
```bash
+ kubectl get svc -n frontend-dev -o wide
NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE    SELECTOR
frontend-frontend   ClusterIP   10.43.174.103   <none>        8080/TCP   106m   app=frontend-frontend
```

### Ingresses
```bash
+ kubectl get ingress -n frontend-dev
NAME                CLASS    HOSTS                ADDRESS        PORTS     AGE
frontend-frontend   <none>   frontend-dev.local   10.43.140.62   80, 443   106m
```

### ConfigMaps
```bash
+ kubectl get configmap -n frontend-dev
NAME                    DATA   AGE
frontend-nginx-config   1      106m
kube-root-ca.crt        1      106m
```

### Secrets
```bash
+ kubectl get secret -n frontend-dev
NAME               TYPE                DATA   AGE
frontend-tls-dev   kubernetes.io/tls   3      106m
```

### Horizontal Pod Autoscalers
```bash
+ kubectl get hpa -n frontend-dev
NAME                REFERENCE                      TARGETS                       MINPODS   MAXPODS   REPLICAS   AGE
frontend-frontend   Deployment/frontend-frontend   cpu: 1%/70%, memory: 3%/80%   1         3         1          106m
```

### Jobs
```bash
+ kubectl get jobs -n frontend-dev
No resources found in frontend-dev namespace.
```

### CronJobs
```bash
+ kubectl get cronjobs -n frontend-dev
No resources found in frontend-dev namespace.
```

### PersistentVolumeClaims
```bash
+ kubectl get pvc -n frontend-dev
No resources found in frontend-dev namespace.
```

### Recent Events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -n\ \"frontend-dev\"\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 20
No resources found in frontend-dev namespace.
```

### Resource Usage (pods)
```bash
+ kubectl top pods -n frontend-dev
NAME                                 CPU(cores)   MEMORY(bytes)   
frontend-frontend-597d68f8cf-jrz92   1m           4Mi             
```


- **Service:** `frontend-frontend`
- **Namespace:** `frontend-dev`
- **Port:** `8080`

**Port-forward command:**
```bash
kubectl port-forward svc/frontend-frontend -n frontend-dev 8080:8080
```

## ‚öôÔ∏è Backend (`backend-dev`)
### Pods
```bash
+ kubectl get pods -n backend-dev -o wide
NAME                              READY   STATUS    RESTARTS   AGE     IP           NODE                     NOMINATED NODE   READINESS GATES
backend-backend-66c96df8b-j8pcg   1/1     Running   0          4m30s   10.42.0.43   k3d-vyking-dev-agent-0   <none>           <none>
backend-backend-66c96df8b-kgsvt   1/1     Running   0          106m    10.42.1.9    k3d-vyking-dev-agent-1   <none>           <none>
```

### Deployments
```bash
+ kubectl get deploy -n backend-dev -o wide
NAME              READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES               SELECTOR
backend-backend   2/2     2            2           106m   backend      vyking-backend:dev   app=backend-backend
```

### StatefulSets
```bash
+ kubectl get statefulset -n backend-dev -o wide
No resources found in backend-dev namespace.
```

### DaemonSets
```bash
+ kubectl get daemonset -n backend-dev -o wide
No resources found in backend-dev namespace.
```

### Services
```bash
+ kubectl get svc -n backend-dev -o wide
NAME              TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE    SELECTOR
backend-backend   ClusterIP   10.43.231.3   <none>        8081/TCP   106m   app=backend-backend
```

### Ingresses
```bash
+ kubectl get ingress -n backend-dev
NAME              CLASS     HOSTS                ADDRESS                            PORTS   AGE
backend-backend   traefik   frontend-dev.local   172.18.0.2,172.18.0.3,172.18.0.4   80      106m
```

### ConfigMaps
```bash
+ kubectl get configmap -n backend-dev
NAME               DATA   AGE
kube-root-ca.crt   1      106m
```

### Secrets
```bash
+ kubectl get secret -n backend-dev
NAME                    TYPE     DATA   AGE
mysql-credentials-dev   Opaque   5      106m
```

### Horizontal Pod Autoscalers
```bash
+ kubectl get hpa -n backend-dev
NAME              REFERENCE                    TARGETS                        MINPODS   MAXPODS   REPLICAS   AGE
backend-backend   Deployment/backend-backend   cpu: 1%/70%, memory: 19%/70%   1         5         2          106m
```

### Jobs
```bash
+ kubectl get jobs -n backend-dev
No resources found in backend-dev namespace.
```

### CronJobs
```bash
+ kubectl get cronjobs -n backend-dev
No resources found in backend-dev namespace.
```

### PersistentVolumeClaims
```bash
+ kubectl get pvc -n backend-dev
No resources found in backend-dev namespace.
```

### Recent Events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -n\ \"backend-dev\"\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 20
20m         Normal   Killing             pod/backend-backend-66c96df8b-gq4cn       Stopping container backend
20m         Normal   Scheduled           pod/backend-backend-66c96df8b-v5fk9       Successfully assigned backend-dev/backend-backend-66c96df8b-v5fk9 to k3d-vyking-dev-agent-0
20m         Normal   Pulled              pod/backend-backend-66c96df8b-v5fk9       Container image "vyking-backend:dev" already present on machine
20m         Normal   Created             pod/backend-backend-66c96df8b-v5fk9       Created container backend
20m         Normal   Started             pod/backend-backend-66c96df8b-v5fk9       Started container backend
15m         Normal   Killing             pod/backend-backend-66c96df8b-v5fk9       Stopping container backend
15m         Normal   Scheduled           pod/backend-backend-66c96df8b-tbwb8       Successfully assigned backend-dev/backend-backend-66c96df8b-tbwb8 to k3d-vyking-dev-agent-0
15m         Normal   Pulled              pod/backend-backend-66c96df8b-tbwb8       Container image "vyking-backend:dev" already present on machine
15m         Normal   Created             pod/backend-backend-66c96df8b-tbwb8       Created container backend
15m         Normal   Started             pod/backend-backend-66c96df8b-tbwb8       Started container backend
9m54s       Normal   Killing             pod/backend-backend-66c96df8b-tbwb8       Stopping container backend
9m49s       Normal   Scheduled           pod/backend-backend-66c96df8b-nbphp       Successfully assigned backend-dev/backend-backend-66c96df8b-nbphp to k3d-vyking-dev-agent-0
9m47s       Normal   Created             pod/backend-backend-66c96df8b-nbphp       Created container backend
9m47s       Normal   Pulled              pod/backend-backend-66c96df8b-nbphp       Container image "vyking-backend:dev" already present on machine
9m46s       Normal   Started             pod/backend-backend-66c96df8b-nbphp       Started container backend
4m36s       Normal   Killing             pod/backend-backend-66c96df8b-nbphp       Stopping container backend
4m33s       Normal   Scheduled           pod/backend-backend-66c96df8b-j8pcg       Successfully assigned backend-dev/backend-backend-66c96df8b-j8pcg to k3d-vyking-dev-agent-0
4m31s       Normal   Created             pod/backend-backend-66c96df8b-j8pcg       Created container backend
4m31s       Normal   Pulled              pod/backend-backend-66c96df8b-j8pcg       Container image "vyking-backend:dev" already present on machine
4m30s       Normal   Started             pod/backend-backend-66c96df8b-j8pcg       Started container backend
```

### Resource Usage (pods)
```bash
+ kubectl top pods -n backend-dev
NAME                              CPU(cores)   MEMORY(bytes)   
backend-backend-66c96df8b-j8pcg   2m           24Mi            
backend-backend-66c96df8b-kgsvt   2m           25Mi            
```


- **Service:** `backend-backend`
- **Namespace:** `backend-dev`
- **Port:** `8081`

**Port-forward command:**
```bash
kubectl port-forward svc/backend-backend -n backend-dev 8081:8081
```

## üõ¢Ô∏è MySQL (`mysql-dev`)
### Pods
```bash
+ kubectl get pods -n mysql-dev -o wide
NAME                          READY   STATUS                       RESTARTS   AGE   IP           NODE                      NOMINATED NODE   READINESS GATES
mysql-0                       1/1     Running                      0          79m   10.42.1.12   k3d-vyking-dev-agent-1    <none>           <none>
mysql-backup-29305295-82k7p   0/1     CreateContainerConfigError   0          15s   10.42.0.44   k3d-vyking-dev-agent-0    <none>           <none>
tmp-shell                     1/1     Running                      0          11m   10.42.2.19   k3d-vyking-dev-server-0   <none>           <none>
```

### Deployments
```bash
+ kubectl get deploy -n mysql-dev -o wide
No resources found in mysql-dev namespace.
```

### StatefulSets
```bash
+ kubectl get statefulset -n mysql-dev -o wide
NAME    READY   AGE   CONTAINERS   IMAGES
mysql   1/1     79m   mysql        docker.io/bitnami/mysql:8.4.4-debian-12-r4
```

### DaemonSets
```bash
+ kubectl get daemonset -n mysql-dev -o wide
No resources found in mysql-dev namespace.
```

### Services
```bash
+ kubectl get svc -n mysql-dev -o wide
NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE   SELECTOR
mysql            ClusterIP   10.43.182.98   <none>        3306/TCP   79m   app.kubernetes.io/component=primary,app.kubernetes.io/instance=mysql,app.kubernetes.io/name=mysql,app.kubernetes.io/part-of=mysql
mysql-headless   ClusterIP   None           <none>        3306/TCP   79m   app.kubernetes.io/component=primary,app.kubernetes.io/instance=mysql,app.kubernetes.io/name=mysql
```

### Ingresses
```bash
+ kubectl get ingress -n mysql-dev
No resources found in mysql-dev namespace.
```

### ConfigMaps
```bash
+ kubectl get configmap -n mysql-dev
NAME               DATA   AGE
kube-root-ca.crt   1      108m
mysql              1      79m
```

### Secrets
```bash
+ kubectl get secret -n mysql-dev
NAME               TYPE     DATA   AGE
mysql              Opaque   2      79m
mysql-dev-secret   Opaque   6      107m
```

### Horizontal Pod Autoscalers
```bash
+ kubectl get hpa -n mysql-dev
No resources found in mysql-dev namespace.
```

### Jobs
```bash
+ kubectl get jobs -n mysql-dev
NAME                    STATUS    COMPLETIONS   DURATION   AGE
mysql-backup-29305295   Running   0/1           20s        20s
```

### CronJobs
```bash
+ kubectl get cronjobs -n mysql-dev
NAME           SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE
mysql-backup   */5 * * * *   <none>     False     1        20s             79m
```

### PersistentVolumeClaims
```bash
+ kubectl get pvc -n mysql-dev
NAME            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
data-mysql-0    Bound    pvc-2300a91d-3838-4354-8dfa-3e859648462a   8Gi        RWO            local-path     <unset>                 79m
mysql-backups   Bound    pvc-4d48fb6d-0b76-4ffb-9cdd-acdd00097e43   2Gi        RWO            local-path     <unset>                 79m
```

### Recent Events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -n\ \"mysql-dev\"\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 20
11m         Normal    Scheduled                pod/tmp-shell                     Successfully assigned mysql-dev/tmp-shell to k3d-vyking-dev-server-0
11m         Normal    Pulling                  pod/tmp-shell                     Pulling image "bitnami/mysql:8.0"
10m         Normal    SuccessfulCreate         job/mysql-backup-29305285         Created pod: mysql-backup-29305285-kx8jm
10m         Normal    Scheduled                pod/mysql-backup-29305285-kx8jm   Successfully assigned mysql-dev/mysql-backup-29305285-kx8jm to k3d-vyking-dev-agent-0
8m3s        Warning   Failed                   pod/mysql-backup-29305285-kx8jm   Error: couldn't find key userPassword in Secret mysql-dev/mysql-dev-secret
7m52s       Normal    Pulled                   pod/mysql-backup-29305285-kx8jm   Container image "bitnami/mysql:8.0" already present on machine
10m         Normal    MissingJob               cronjob/mysql-backup              Active job went missing: mysql-backup-29305280
8m51s       Normal    Pulled                   pod/tmp-shell                     Successfully pulled image "bitnami/mysql:8.0" in 3m0.581s (3m0.582s including waiting). Image size: 239770540 bytes.
8m51s       Normal    Created                  pod/tmp-shell                     Created container tmp-shell
8m51s       Normal    Started                  pod/tmp-shell                     Started container tmp-shell
6m7s        Normal    MissingJob               cronjob/mysql-backup              Active job went missing: mysql-backup-29305285
5m21s       Normal    Scheduled                pod/mysql-backup-29305290-2d9vr   Successfully assigned mysql-dev/mysql-backup-29305290-2d9vr to k3d-vyking-dev-agent-0
5m21s       Normal    SuccessfulCreate         job/mysql-backup-29305290         Created pod: mysql-backup-29305290-2d9vr
3m6s        Normal    Pulled                   pod/mysql-backup-29305290-2d9vr   Container image "bitnami/mysql:8.0" already present on machine
3m6s        Warning   Failed                   pod/mysql-backup-29305290-2d9vr   Error: couldn't find key userPassword in Secret mysql-dev/mysql-dev-secret
3m2s        Normal    MissingJob               cronjob/mysql-backup              Active job went missing: mysql-backup-29305290
21s         Normal    SuccessfulCreate         job/mysql-backup-29305295         Created pod: mysql-backup-29305295-82k7p
21s         Normal    Scheduled                pod/mysql-backup-29305295-82k7p   Successfully assigned mysql-dev/mysql-backup-29305295-82k7p to k3d-vyking-dev-agent-0
7s          Normal    Pulled                   pod/mysql-backup-29305295-82k7p   Container image "bitnami/mysql:8.0" already present on machine
7s          Warning   Failed                   pod/mysql-backup-29305295-82k7p   Error: couldn't find key userPassword in Secret mysql-dev/mysql-dev-secret
```

### Resource Usage (pods)
```bash
+ kubectl top pods -n mysql-dev
NAME        CPU(cores)   MEMORY(bytes)   
mysql-0     44m          434Mi           
tmp-shell   0m           0Mi             
```


- **Service:** `mysql`
- **Namespace:** `mysql-dev`
- **Port:** `3306`

**Connection test command:**
```bash
kubectl run mysql-client --rm -it --image=bitnami/mysql:8.0 -n mysql-dev --env MYSQL_HOST=mysql -- bash
```

**Port-forward command:**
```bash
kubectl port-forward svc/mysql -n mysql-dev 3306:3306
```

## üîê Cert-Manager (`cert-manager`)
### Pods
```bash
+ kubectl get pods -n cert-manager -o wide
NAME                                       READY   STATUS    RESTARTS   AGE    IP          NODE                      NOMINATED NODE   READINESS GATES
cert-manager-55c69bf5cf-jzfd4              1/1     Running   0          108m   10.42.0.7   k3d-vyking-dev-agent-0    <none>           <none>
cert-manager-cainjector-5765b5f544-hjj6k   1/1     Running   0          108m   10.42.2.9   k3d-vyking-dev-server-0   <none>           <none>
cert-manager-webhook-6b67444dc9-k2q5r      1/1     Running   0          108m   10.42.1.8   k3d-vyking-dev-agent-1    <none>           <none>
```

### Deployments
```bash
+ kubectl get deploy -n cert-manager -o wide
NAME                      READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS                IMAGES                                             SELECTOR
cert-manager              1/1     1            1           108m   cert-manager-controller   quay.io/jetstack/cert-manager-controller:v1.16.1   app.kubernetes.io/component=controller,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=cert-manager
cert-manager-cainjector   1/1     1            1           108m   cert-manager-cainjector   quay.io/jetstack/cert-manager-cainjector:v1.16.1   app.kubernetes.io/component=cainjector,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=cainjector
cert-manager-webhook      1/1     1            1           108m   cert-manager-webhook      quay.io/jetstack/cert-manager-webhook:v1.16.1      app.kubernetes.io/component=webhook,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=webhook
```

### StatefulSets
```bash
+ kubectl get statefulset -n cert-manager -o wide
No resources found in cert-manager namespace.
```

### DaemonSets
```bash
+ kubectl get daemonset -n cert-manager -o wide
No resources found in cert-manager namespace.
```

### Services
```bash
+ kubectl get svc -n cert-manager -o wide
NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)            AGE    SELECTOR
cert-manager              ClusterIP   10.43.211.209   <none>        9402/TCP           108m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=cert-manager
cert-manager-cainjector   ClusterIP   10.43.14.233    <none>        9402/TCP           108m   app.kubernetes.io/component=cainjector,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=cainjector
cert-manager-webhook      ClusterIP   10.43.193.48    <none>        443/TCP,9402/TCP   108m   app.kubernetes.io/component=webhook,app.kubernetes.io/instance=cert-manager,app.kubernetes.io/name=webhook
```

### Ingresses
```bash
+ kubectl get ingress -n cert-manager
No resources found in cert-manager namespace.
```

### ConfigMaps
```bash
+ kubectl get configmap -n cert-manager
NAME               DATA   AGE
kube-root-ca.crt   1      108m
```

### Secrets
```bash
+ kubectl get secret -n cert-manager
NAME                                 TYPE                 DATA   AGE
cert-manager-webhook-ca              Opaque               3      107m
sh.helm.release.v1.cert-manager.v1   helm.sh/release.v1   1      108m
```

### Horizontal Pod Autoscalers
```bash
+ kubectl get hpa -n cert-manager
No resources found in cert-manager namespace.
```

### Jobs
```bash
+ kubectl get jobs -n cert-manager
No resources found in cert-manager namespace.
```

### CronJobs
```bash
+ kubectl get cronjobs -n cert-manager
No resources found in cert-manager namespace.
```

### PersistentVolumeClaims
```bash
+ kubectl get pvc -n cert-manager
No resources found in cert-manager namespace.
```

### Recent Events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -n\ \"cert-manager\"\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 20
No resources found in cert-manager namespace.
```

### Resource Usage (pods)
```bash
+ kubectl top pods -n cert-manager
NAME                                       CPU(cores)   MEMORY(bytes)   
cert-manager-55c69bf5cf-jzfd4              5m           23Mi            
cert-manager-cainjector-5765b5f544-hjj6k   5m           22Mi            
cert-manager-webhook-6b67444dc9-k2q5r      1m           12Mi            
```


## üîÑ Sealed Secrets (`kube-system`)
### Sealed Secrets pods
```bash
+ kubectl get pods -n kube-system -l name=sealed-secrets-controller -o wide
NAME                                         READY   STATUS    RESTARTS   AGE    IP          NODE                     NOMINATED NODE   READINESS GATES
sealed-secrets-controller-5655858cbc-9xzgr   1/1     Running   0          123m   10.42.0.3   k3d-vyking-dev-agent-0   <none>           <none>
```

### Sealed Secrets deployment
```bash
+ kubectl get deploy -n kube-system -l name=sealed-secrets-controller -o wide
NAME                        READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS                  IMAGES                                               SELECTOR
sealed-secrets-controller   1/1     1            1           123m   sealed-secrets-controller   docker.io/bitnami/sealed-secrets-controller:0.26.0   name=sealed-secrets-controller
```

### Sealed Secrets service
```bash
+ kubectl get svc -n kube-system -l name=sealed-secrets-controller -o wide
NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE    SELECTOR
sealed-secrets-controller   ClusterIP   10.43.252.105   <none>        8080/TCP   123m   name=sealed-secrets-controller
```

### Recent kube-system events
```bash
+ bash -lc set\ -o\ pipefail\;\ kubectl\ get\ events\ -n\ kube-system\ --sort-by=.metadata.creationTimestamp\ \|\ tail\ -n\ 40
LAST SEEN   TYPE      REASON      OBJECT                                MESSAGE
28m         Warning   Unhealthy   pod/metrics-server-5985cbc9d7-hsgtx   Readiness probe failed: Get "https://10.42.0.2:10250/readyz": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
```


## üöÄ Workload Rollouts
### Namespace `argocd-dev`
### Deployment argocd-applicationset-controller
```bash
+ kubectl rollout status deploy argocd-applicationset-controller -n argocd-dev --timeout=30s
deployment "argocd-applicationset-controller" successfully rolled out
```

### Deployment argocd-dex-server
```bash
+ kubectl rollout status deploy argocd-dex-server -n argocd-dev --timeout=30s
deployment "argocd-dex-server" successfully rolled out
```

### Deployment argocd-notifications-controller
```bash
+ kubectl rollout status deploy argocd-notifications-controller -n argocd-dev --timeout=30s
deployment "argocd-notifications-controller" successfully rolled out
```

### Deployment argocd-redis
```bash
+ kubectl rollout status deploy argocd-redis -n argocd-dev --timeout=30s
deployment "argocd-redis" successfully rolled out
```

### Deployment argocd-repo-server
```bash
+ kubectl rollout status deploy argocd-repo-server -n argocd-dev --timeout=30s
deployment "argocd-repo-server" successfully rolled out
```

### Deployment argocd-server
```bash
+ kubectl rollout status deploy argocd-server -n argocd-dev --timeout=30s
deployment "argocd-server" successfully rolled out
```

### StatefulSet argocd-application-controller
```bash
+ kubectl rollout status statefulset argocd-application-controller -n argocd-dev --timeout=30s
partitioned roll out complete: 1 new pods have been updated...
```


### Namespace `frontend-dev`
### Deployment frontend-frontend
```bash
+ kubectl rollout status deploy frontend-frontend -n frontend-dev --timeout=30s
deployment "frontend-frontend" successfully rolled out
```


### Namespace `backend-dev`
### Deployment backend-backend
```bash
+ kubectl rollout status deploy backend-backend -n backend-dev --timeout=30s
deployment "backend-backend" successfully rolled out
```


### Namespace `mysql-dev`
### StatefulSet mysql
```bash
+ kubectl rollout status statefulset mysql -n mysql-dev --timeout=30s
statefulset rolling update complete 1 pods at revision mysql-844bc6b877...
```


### Namespace `cert-manager`
### Deployment cert-manager
```bash
+ kubectl rollout status deploy cert-manager -n cert-manager --timeout=30s
deployment "cert-manager" successfully rolled out
```

### Deployment cert-manager-cainjector
```bash
+ kubectl rollout status deploy cert-manager-cainjector -n cert-manager --timeout=30s
deployment "cert-manager-cainjector" successfully rolled out
```

### Deployment cert-manager-webhook
```bash
+ kubectl rollout status deploy cert-manager-webhook -n cert-manager --timeout=30s
deployment "cert-manager-webhook" successfully rolled out
```


### Namespace `kube-system`
### Deployment coredns
```bash
+ kubectl rollout status deploy coredns -n kube-system --timeout=30s
deployment "coredns" successfully rolled out
```

### Deployment local-path-provisioner
```bash
+ kubectl rollout status deploy local-path-provisioner -n kube-system --timeout=30s
deployment "local-path-provisioner" successfully rolled out
```

### Deployment metrics-server
```bash
+ kubectl rollout status deploy metrics-server -n kube-system --timeout=30s
deployment "metrics-server" successfully rolled out
```

### Deployment sealed-secrets-controller
```bash
+ kubectl rollout status deploy sealed-secrets-controller -n kube-system --timeout=30s
deployment "sealed-secrets-controller" successfully rolled out
```

### Deployment traefik
```bash
+ kubectl rollout status deploy traefik -n kube-system --timeout=30s
deployment "traefik" successfully rolled out
```

### DaemonSet svclb-traefik-5d2bd1f3
```bash
+ kubectl rollout status daemonset svclb-traefik-5d2bd1f3 -n kube-system --timeout=30s
daemon set "svclb-traefik-5d2bd1f3" successfully rolled out
```


‚úÖ Tests complete.
